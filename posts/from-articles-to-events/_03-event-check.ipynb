{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: From Articles to Events, Part III\n",
    "date: 2024-03-11\n",
    "description: Categorizing texts with an LLM\n",
    "categories: [OpenAI, Articles to Events]\n",
    "draft: false\n",
    "image: newspaper-protest.webp\n",
    "author-meta: Neal Caren, Associate Professor, Department of Sociology, University of North Carolina, Chapel Hill\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one post in a series where I'm working to expand the working paper \"[Extracting protest events from newspaper articles with ChatGPT](https://osf.io/dvht7)\" I wrote with Andy Andrews and Rashawn Ray. In that paper, we tested whether ChatGPT could replace my undergraduate RAs in extracting details about Black Lives Matter protests from media accounts. This time, I want to expand it to include more articles, movements, and variables.\n",
    "\n",
    "**Earlier Installments** \n",
    "* Part 1: [From Articles to Events](https://nealcaren.github.io/notes/posts/from-articles-to-events/01-downloading-articles.html)\n",
    "* Part 2: [Extracting text from media HTML files](https://nealcaren.github.io/notes/posts/from-articles-to-events/02-extracting-text.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I'm want to check whether the file I downloaded actually contains a media account of a protest that already happened. I'm hoping to filter out a few types of bad texts: files where I downloaded \"You can't see this page without paying.\" instead of the article; articles about future events; and pages that are organizational listings of events rather than media accounts. The plan is to use ChatGPT to categorize the articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the article dataset made in [step 2]((https://nealcaren.github.io/notes/posts/from-articles-to-events/02-extracting-text.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('https://github.com/nealcaren/notes/raw/main/posts/from-articles-to-events/article_texts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>site</th>\n",
       "      <th>publisher</th>\n",
       "      <th>file_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>Man refuses to get off his Fort Myers Beach ro...</td>\n",
       "      <td>Video Player is loading. Play Video Play Skip ...</td>\n",
       "      <td>https://winknews.com/2023/08/02/roof-fort-myer...</td>\n",
       "      <td>[Michael Hudak]</td>\n",
       "      <td>2023-08-02T00:00:00.000</td>\n",
       "      <td>Rick Loughery is refusing to get off the roof ...</td>\n",
       "      <td>WINK News</td>\n",
       "      <td>{}</td>\n",
       "      <td>_HTML/https-winknews-com-2023-08-02-roof-fort-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>Bigger Than Roe- Missoula</td>\n",
       "      <td>We are ALL born free and equal in dignity and ...</td>\n",
       "      <td>https://action.womensmarch.com/events/bigger-t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Women's March</td>\n",
       "      <td>{}</td>\n",
       "      <td>_HTML/https-action-womensmarch-com-events-bigg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Trump says Jack Smith a 'deranged lunatic' dur...</td>\n",
       "      <td>WINDHAM, N.H. — Former President Donald Trump ...</td>\n",
       "      <td>https://www.bostonherald.com/2023/08/08/trump-...</td>\n",
       "      <td>[Matthew Medsger]</td>\n",
       "      <td>2023-08-08T00:00:00.000</td>\n",
       "      <td>On Friday the Special Counsel, who the preside...</td>\n",
       "      <td>Boston Herald</td>\n",
       "      <td>{}</td>\n",
       "      <td>_HTML/https-www-bostonherald-com-2023-08-08-tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "2486  Man refuses to get off his Fort Myers Beach ro...   \n",
       "1878                          Bigger Than Roe- Missoula   \n",
       "516   Trump says Jack Smith a 'deranged lunatic' dur...   \n",
       "\n",
       "                                                   text  \\\n",
       "2486  Video Player is loading. Play Video Play Skip ...   \n",
       "1878  We are ALL born free and equal in dignity and ...   \n",
       "516   WINDHAM, N.H. — Former President Donald Trump ...   \n",
       "\n",
       "                                                    url            authors  \\\n",
       "2486  https://winknews.com/2023/08/02/roof-fort-myer...    [Michael Hudak]   \n",
       "1878  https://action.womensmarch.com/events/bigger-t...                 []   \n",
       "516   https://www.bostonherald.com/2023/08/08/trump-...  [Matthew Medsger]   \n",
       "\n",
       "                         date  \\\n",
       "2486  2023-08-02T00:00:00.000   \n",
       "1878                     None   \n",
       "516   2023-08-08T00:00:00.000   \n",
       "\n",
       "                                            description           site  \\\n",
       "2486  Rick Loughery is refusing to get off the roof ...      WINK News   \n",
       "1878                                                     Women's March   \n",
       "516   On Friday the Special Counsel, who the preside...  Boston Herald   \n",
       "\n",
       "     publisher                                      file_location  \n",
       "2486        {}  _HTML/https-winknews-com-2023-08-02-roof-fort-...  \n",
       "1878        {}  _HTML/https-action-womensmarch-com-events-bigg...  \n",
       "516         {}  _HTML/https-www-bostonherald-com-2023-08-08-tr...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than ask a single question, \"Is this an media article that describes a protest event that has already happened or is ongoing?\" I decided to ask it three separate questions. I *think* this strategy of breaking the question down into its component parts will lead to more accurate answers. \n",
    "\n",
    "To provide information about the questions and the format of a response (`True`/`False`), I use the `pydantic` library to create the structure of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleReview(BaseModel):\n",
    "    discusses_political_protest: bool = Field(\n",
    "        ...,\n",
    "        description=\"Indicates whether the article discusses a political protest. True if it does, False otherwise.\"\n",
    "    )\n",
    "    from_media_source: bool = Field(\n",
    "        ...,\n",
    "        description=\"Determines if the article is from a media source. Respond False if it is a press release or event listing.\"\n",
    "    )\n",
    "    protest_event_future: bool = Field(\n",
    "        ...,\n",
    "        description=\"Is the event planned for the future? Respond false if the event occurred or is currently happening.\"\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a Python function to call the OpenAI ChatGPT model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_protest(article_info, client):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that extracts summaries of newspaper articles about political protests as JSON for a database. \",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Extract information about the details about a protest from the following article.\n",
    "      Only use information from the article.\n",
    "\n",
    "      {article_info}\n",
    "      \n",
    "      \"\"\",\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"protest_details\",\n",
    "                \"description\": \"Extract insights from media article about protest.\",\n",
    "                \"parameters\": ArticleReview.model_json_schema(),\n",
    "            }\n",
    "        ],\n",
    "        n=1,\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    r = json.loads(completion.choices[0].message.function_call.arguments)\n",
    "\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, I include the client as part of the function but this time I wanted to pass it to the function so it is only called once. That should speed things up a tiny bit. Plus, down the road I was thinking about using non-OpenAI models from [anyscale](https://www.anyscale.com) and this might make that easier to add on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    max_retries=3,\n",
    "    timeout=20.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        n=3,\n",
    "        logprobs=True,\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a high school guidance counselor working in the poorest neighborhood of Greensboro, NC.  You specializing in matching students with the college that would be the best fit for them. Respond only with the name of the college.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Steve is a low performing student with high SAT scores. He is deciding between NC State and UNC-Chapel Hill. Which should he pick? \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        n=5,\n",
    "        logprobs=True,\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a high school guidance counselor working. You specializing in matching students with the college that would be the best fit for them. Respond only with the name of the college.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Which school is more prestigious? University of Wisconsin or University of North Carolina, Chapel Hill? \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab a sample article, including only the fields I want to process. I also truncate the text length to save $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'University of North Carolina, Chapel Hill': 5})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([m.message.content for m in completion.choices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Faces of protest: Thursday at the Indiana Statehouse',\n",
       " 'text': \"We are The Statehouse File\\n\\nFrom an office in the Press Corps of the Indiana Statehouse, the journalism majors of Franklin College's Pulliam School of Journalism work alongside the pros, digging into the behind-the-scenes stories of Indiana politics. We're a student newsroom, but our work doesn't sit on a professor's desk. We create daily content for this website and professional media outlets around the state.\\n\\nUSE OUR CONTENT FOR FREE: Thanks to a $180,000 grant from Lumina, TheStatehouseFile.com has taken down its reader paywall and is offering its year-round coverage of the Indiana Statehouse to professional media outlets to republish for free. Just retain the author's and The Statehouse File's name, helping our young journalists on their way.\",\n",
       " 'date': None,\n",
       " 'site': 'The Statehouse File'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful = ['title', 'text','date','site']\n",
    "a = df[useful].sample().to_dict(orient='records')[0]\n",
    "a['text'] = a['text'][:2000]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying it out! I ran these surrounding cells a couple of times to make sure it works for different kinds or articles. Results seem good. A prior version used asked about `protest_event_past` but that seemed to miss a few, so I changed the question around in this version to ask only if the event was in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discusses_political_protest': False,\n",
       " 'from_media_source': True,\n",
       " 'protest_event_future': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_protest(a, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want to apply the function to the whole dataframe. I had ChatGPT help me out here because I wanted a function that would (1) make multiple calls to the API at the same time to speed things up, and (2) be able to pick up where I left off in case I closed my laptop during the process. After some negotiation, the solution we agreed upon was one where it created a new feature `api_called` that would start as `false` but then be switched to `true` when the API was successfully called.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to be executed by each thread\n",
    "def process_row(index, row):\n",
    "    useful = ['title', 'date','site','text_truncated']\n",
    "    if not row['api_called']:\n",
    "        text = row['text_truncated']\n",
    "        result = is_protest(row[useful], client)\n",
    "        return (index, result)\n",
    "    return (index, None)\n",
    "\n",
    "# Function to execute API calls in parallel and update DataFrame\n",
    "def update_dataframe(df):\n",
    "    # Select rows where API call hasn't been made\n",
    "    rows_to_process = df[~df['api_called']].copy()\n",
    "    \n",
    "    # Use ThreadPoolExecutor to parallelize API calls\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit tasks\n",
    "        futures = {executor.submit(process_row, index, row): index for index, row in rows_to_process.iterrows()}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                index, api_result = result\n",
    "                # Update DataFrame with the result\n",
    "                for key, value in api_result.items():\n",
    "                    if key not in df.columns:\n",
    "                        df[key] = pd.NA  # Initialize new column with missing values\n",
    "                    df.at[index, key] = value\n",
    "                \n",
    "                # Mark the row as processed\n",
    "                df.at[index, 'api_called'] = True\n",
    "\n",
    "# Truncate 'text' to 2000 characters and initialize 'api_called' column\n",
    "df['text_truncated'] = df['text'].str[:2000]\n",
    "df['api_called'] = False\n",
    "\n",
    "# Update the DataFrame with API call results\n",
    "update_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 9 minutes to process, which works about to be about .2 second for each record. Using `ThreadPoolExecutor` allowed me to make 5 API calls at a time, so if I hadn't used it, the process would have taken 45 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a new variable for the articles that match all the conditions that I want, and save those as a new JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_conditions_met'] = (\n",
    "    (df['discusses_political_protest'] == True) & \n",
    "    (df['from_media_source'] == True) & \n",
    "    (df['protest_event_future'] == False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4548115623856568"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_conditions_met'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1243"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_conditions_met'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = df['all_conditions_met']==True\n",
    "df[screen].to_json('protest_articles.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data prep is done! I have about the full text of 1,243 articles that are already coded by CCC for use in testing out the accuracy of LLMs for my use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
